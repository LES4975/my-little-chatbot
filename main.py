#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ë¼ì¦ˆë² ë¦¬íŒŒì´ FastAPI ì„œë²„
ì™¸ë¶€ì—ì„œ ë¡œë´‡ ì œì–´ ìš”ì²­ì„ ë°›ì•„ STT â†’ GPU ì„œë²„ í†µì‹  â†’ TTS ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
"""

import os
import asyncio
import requests
import json
import time
from typing import Dict, Optional
from fastapi import FastAPI, HTTPException, BackgroundTasks
from pydantic import BaseModel
from dotenv import load_dotenv
from stt import STTTester
from tts import GoogleTTSClient

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# FastAPI ì•± ì´ˆê¸°í™”
app = FastAPI(
    title="Robot Conversation API",
    description="ë¼ì¦ˆë² ë¦¬íŒŒì´ ê¸°ë°˜ ëŒ€í™”í˜• ë¡œë´‡ ì œì–´ API",
    version="1.0.0"
)

# ìš”ì²­/ì‘ë‹µ ëª¨ë¸ ì •ì˜
class ConversationRequest(BaseModel):
    user_id: Optional[str] = "anonymous"
    session_id: Optional[str] = None
    max_length: Optional[int] = 512
    temperature: Optional[float] = 0.7

class ConversationResponse(BaseModel):
    status: str
    message: str
    user_text: Optional[str] = None
    llm_response: Optional[str] = None
    processing_time: Optional[float] = None
    session_id: Optional[str] = None

class StatusResponse(BaseModel):
    status: str
    message: str
    system_info: Dict

# ì „ì—­ ë³€ìˆ˜
robot_system = None

class RobotConversationSystem:
    def __init__(self):
        """ë¡œë´‡ ëŒ€í™” ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        # GPU ì„œë²„ ì„¤ì •
        self.gpu_server_url = os.getenv('GPU_SERVER_URL', 'http://localhost:8000')
        self.gpu_server_endpoint = f"{self.gpu_server_url}/api/chat"
        
        # í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.stt_client = None
        self.tts_client = None
        self.is_busy = False
        
        print("ğŸ¤– ë¡œë´‡ ëŒ€í™” ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"ğŸŒ GPU ì„œë²„: {self.gpu_server_url}")
    
    async def initialize_clients(self):
        """STT, TTS í´ë¼ì´ì–¸íŠ¸ ë¹„ë™ê¸° ì´ˆê¸°í™”"""
        try:
            if self.stt_client is None:
                print("ğŸ¤ STT í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì¤‘...")
                self.stt_client = STTTester()
                print("âœ… STT í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
            
            if self.tts_client is None:
                print("ğŸ”Š TTS í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì¤‘...")
                self.tts_client = GoogleTTSClient()
                print("âœ… TTS í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
            
            return True
            
        except Exception as e:
            print(f"âŒ í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
    
    async def get_user_speech(self):
        """ì‚¬ìš©ì ìŒì„± ì…ë ¥ ë°›ê¸°"""
        try:
            print("ğŸ¯ ìŒì„± ì…ë ¥ ì‹œì‘")
            
            # STT ì‹¤í–‰ (ê°„ì†Œí™”ëœ ë°©ë²• ì‚¬ìš©)
            loop = asyncio.get_event_loop()
            transcript = await loop.run_in_executor(
                None, 
                self.stt_client.simple_record_and_transcribe, 
                False  # show_progress=False
            )
            
            if transcript:
                print(f"âœ… ìŒì„± ì¸ì‹ ì™„ë£Œ: '{transcript}'")
                return transcript
            else:
                print("âŒ ìŒì„± ì¸ì‹ ì‹¤íŒ¨")
                return None
                
        except Exception as e:
            print(f"âŒ ìŒì„± ì…ë ¥ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            return None
    
    async def send_to_gpu_server(self, user_text: str, request_params: Dict):
        """GPU ì„œë²„ë¡œ í…ìŠ¤íŠ¸ ì „ì†¡ ë° ì‘ë‹µ ë°›ê¸°"""
        try:
            print("ğŸŒ GPU ì„œë²„ í†µì‹  ì‹œì‘")
            
            # ìš”ì²­ ë°ì´í„° êµ¬ì„±
            request_data = {
                "message": user_text,
                "user_id": request_params.get("user_id", "raspberry_pi_user"),
                "session_id": request_params.get("session_id", f"session_{int(time.time())}"),
                "max_length": request_params.get("max_length", 512),
                "temperature": request_params.get("temperature", 0.7)
            }
            
            print(f"ğŸ“¤ GPU ì„œë²„ë¡œ ì „ì†¡: '{user_text[:50]}{'...' if len(user_text) > 50 else ''}'")
            
            # ë¹„ë™ê¸° HTTP ìš”ì²­
            loop = asyncio.get_event_loop()
            response = await loop.run_in_executor(
                None,
                lambda: requests.post(
                    self.gpu_server_endpoint,
                    json=request_data,
                    timeout=30
                )
            )
            
            # ì‘ë‹µ ì²˜ë¦¬
            if response.status_code == 200:
                response_data = response.json()
                
                if response_data.get('status') == 'success':
                    llm_response = response_data.get('response', '')
                    processing_time = response_data.get('processing_time', 0)
                    
                    print(f"âœ… GPU ì„œë²„ ì‘ë‹µ ìˆ˜ì‹  ì™„ë£Œ (ì²˜ë¦¬ì‹œê°„: {processing_time:.2f}ì´ˆ)")
                    return llm_response, processing_time
                else:
                    print(f"âŒ GPU ì„œë²„ ì²˜ë¦¬ ì˜¤ë¥˜: {response_data.get('message', 'Unknown error')}")
                    return None, 0
            else:
                print(f"âŒ HTTP ìš”ì²­ ì‹¤íŒ¨: {response.status_code}")
                return None, 0
                
        except requests.exceptions.Timeout:
            print("âŒ GPU ì„œë²„ ì‘ë‹µ ì‹œê°„ ì´ˆê³¼ (30ì´ˆ)")
            return None, 0
        except Exception as e:
            print(f"âŒ GPU ì„œë²„ í†µì‹  ì¤‘ ì˜¤ë¥˜: {e}")
            return None, 0
    
    async def speak_response(self, response_text: str):
        """ì‘ë‹µ í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì¬ìƒ"""
        try:
            print("ğŸ”Š ìŒì„± ì‘ë‹µ ìƒì„± ë° ì¬ìƒ ì‹œì‘")
            
            # TTS ë³€í™˜ ë° ì¬ìƒ (ê°„ì†Œí™”ëœ ë°©ë²• ì‚¬ìš©)
            output_file = "./audio_test/robot_response.mp3"
            loop = asyncio.get_event_loop()
            
            success = await loop.run_in_executor(
                None,
                self.tts_client.simple_text_to_speech_and_play,
                response_text,
                output_file,
                False  # show_progress=False
            )
            
            if success:
                print("âœ… ìŒì„± ì¬ìƒ ì™„ë£Œ")
                return True
            else:
                print("âŒ ìŒì„± ì¬ìƒ ì‹¤íŒ¨")
                return False
                
        except Exception as e:
            print(f"âŒ ìŒì„± ì‘ë‹µ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            return False
    
    async def run_full_conversation(self, request_params: Dict):
        """ì „ì²´ ëŒ€í™” ì›Œí¬í”Œë¡œìš° ì‹¤í–‰"""
        if self.is_busy:
            return {
                "status": "error",
                "message": "ë¡œë´‡ì´ í˜„ì¬ ë‹¤ë¥¸ ëŒ€í™”ë¥¼ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤.",
                "processing_time": 0
            }
        
        self.is_busy = True
        start_time = time.time()
        
        try:
            print("ğŸš€ ëŒ€í™” ì›Œí¬í”Œë¡œìš° ì‹œì‘")
            
            # í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
            if not await self.initialize_clients():
                return {
                    "status": "error",
                    "message": "ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨",
                    "processing_time": time.time() - start_time
                }
            
            # 1ë‹¨ê³„: ì‚¬ìš©ì ìŒì„± ì…ë ¥
            user_text = await self.get_user_speech()
            if not user_text:
                return {
                    "status": "error",
                    "message": "ìŒì„± ì…ë ¥ ì‹¤íŒ¨",
                    "processing_time": time.time() - start_time
                }
            
            # 2ë‹¨ê³„: GPU ì„œë²„ í†µì‹ 
            llm_response, llm_processing_time = await self.send_to_gpu_server(user_text, request_params)
            if not llm_response:
                return {
                    "status": "error",
                    "message": "GPU ì„œë²„ í†µì‹  ì‹¤íŒ¨",
                    "user_text": user_text,
                    "processing_time": time.time() - start_time
                }
            
            # 3ë‹¨ê³„: ìŒì„± ì‘ë‹µ ì¬ìƒ
            speech_success = await self.speak_response(llm_response)
            
            total_time = time.time() - start_time
            
            if speech_success:
                print("ğŸ‰ ëŒ€í™” ì™„ë£Œ!")
                return {
                    "status": "success",
                    "message": "ëŒ€í™”ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.",
                    "user_text": user_text,
                    "llm_response": llm_response,
                    "processing_time": total_time,
                    "session_id": request_params.get("session_id")
                }
            else:
                return {
                    "status": "partial_success",
                    "message": "LLM ì‘ë‹µì€ ë°›ì•˜ì§€ë§Œ ìŒì„± ì¬ìƒì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.",
                    "user_text": user_text,
                    "llm_response": llm_response,
                    "processing_time": total_time,
                    "session_id": request_params.get("session_id")
                }
                
        except Exception as e:
            return {
                "status": "error",
                "message": f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}",
                "processing_time": time.time() - start_time
            }
        finally:
            self.is_busy = False
    
    def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        try:
            if self.stt_client:
                self.stt_client.cleanup()
            print("ğŸ§¹ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")
        except Exception as e:
            print(f"âš ï¸ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

# API ì—”ë“œí¬ì¸íŠ¸ ì •ì˜

@app.on_event("startup")
async def startup_event():
    """ì„œë²„ ì‹œì‘ ì‹œ ì´ˆê¸°í™”"""
    global robot_system
    
    # í•„ìˆ˜ í™˜ê²½ ë³€ìˆ˜ í™•ì¸
    required_vars = ['OPENAI_API_KEY', 'GOOGLE_APPLICATION_CREDENTIALS']
    missing_vars = [var for var in required_vars if not os.getenv(var)]
    
    if missing_vars:
        print("âŒ í•„ìˆ˜ í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤:")
        for var in missing_vars:
            print(f"   - {var}")
        raise RuntimeError("í™˜ê²½ ë³€ìˆ˜ ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.")
    
    # ì˜¤ë””ì˜¤ ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs("./audio_test", exist_ok=True)
    
    # ë¡œë´‡ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    robot_system = RobotConversationSystem()
    print("ğŸŠ ì„œë²„ê°€ ì„±ê³µì ìœ¼ë¡œ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤!")

@app.on_event("shutdown")
async def shutdown_event():
    """ì„œë²„ ì¢…ë£Œ ì‹œ ì •ë¦¬"""
    global robot_system
    if robot_system:
        robot_system.cleanup()
    print("ğŸ‘‹ ì„œë²„ê°€ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

@app.get("/", response_model=StatusResponse)
async def root():
    """ì„œë²„ ìƒíƒœ í™•ì¸"""
    return StatusResponse(
        status="running",
        message="ë¼ì¦ˆë² ë¦¬íŒŒì´ ë¡œë´‡ ëŒ€í™” ì‹œìŠ¤í…œì´ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤.",
        system_info={
            "gpu_server_url": robot_system.gpu_server_url if robot_system else "Not initialized",
            "is_busy": robot_system.is_busy if robot_system else False,
            "clients_initialized": {
                "stt": robot_system.stt_client is not None if robot_system else False,
                "tts": robot_system.tts_client is not None if robot_system else False
            }
        }
    )

@app.post("/api/start_conversation", response_model=ConversationResponse)
async def start_conversation(request: ConversationRequest):
    """ëŒ€í™” ì‹œì‘ (ì „ì²´ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰)"""
    global robot_system
    
    if not robot_system:
        raise HTTPException(status_code=500, detail="ë¡œë´‡ ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    print(f"ğŸ“ ìƒˆë¡œìš´ ëŒ€í™” ìš”ì²­: ì‚¬ìš©ì {request.user_id}")
    
    # ì „ì²´ ëŒ€í™” ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
    result = await robot_system.run_full_conversation(request.dict())
    
    return ConversationResponse(**result)

@app.post("/api/emergency_stop")
async def emergency_stop():
    """ë¹„ìƒ ì •ì§€"""
    global robot_system
    
    if robot_system:
        robot_system.is_busy = False
        print("ğŸ›‘ ë¹„ìƒ ì •ì§€ ì‹¤í–‰")
        return {"status": "success", "message": "ë¹„ìƒ ì •ì§€ê°€ ì‹¤í–‰ë˜ì—ˆìŠµë‹ˆë‹¤."}
    else:
        raise HTTPException(status_code=500, detail="ë¡œë´‡ ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

@app.get("/api/status", response_model=StatusResponse)
async def get_status():
    """ìƒì„¸ ì‹œìŠ¤í…œ ìƒíƒœ ì¡°íšŒ"""
    global robot_system
    
    if not robot_system:
        raise HTTPException(status_code=500, detail="ë¡œë´‡ ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    return StatusResponse(
        status="running",
        message="ì‹œìŠ¤í…œì´ ì •ìƒ ì‘ë™ ì¤‘ì…ë‹ˆë‹¤.",
        system_info={
            "gpu_server_url": robot_system.gpu_server_url,
            "is_busy": robot_system.is_busy,
            "clients_initialized": {
                "stt": robot_system.stt_client is not None,
                "tts": robot_system.tts_client is not None
            }
        }
    )

if __name__ == "__main__":
    import uvicorn
    
    print("ğŸš€ ë¼ì¦ˆë² ë¦¬íŒŒì´ ë¡œë´‡ ëŒ€í™” ì„œë²„ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
    uvicorn.run(
        "main:app",
        host="0.0.0.0",  # ëª¨ë“  IPì—ì„œ ì ‘ê·¼ ê°€ëŠ¥
        port=8080,       # ë¼ì¦ˆë² ë¦¬íŒŒì´ ì„œë²„ í¬íŠ¸
        reload=False,    # í”„ë¡œë•ì…˜ì—ì„œëŠ” False
        log_level="info"
    )